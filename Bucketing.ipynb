{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f30693a-e99f-4f59-994b-ee172cbbdedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3a6cf8-8c88-4e85-b822-929362e2152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing CSV files\n",
    "folder_path = r\"D:\\Stelco\\Work\\Dynamic Correlation\\Key\\Whole_Phase_Good_Clustered_Filtered\"\n",
    "signal_names = [\n",
    "    'Stand 1 Predicted Run Force',\n",
    "    'Stand 1 Gap Stick Offset',\n",
    "    'Tension Reel Calculated Tension',\n",
    "    'Tension To Gap 2 In Limit',\n",
    "    'Stand 1-2 Total Tension Feedback',\n",
    "    'Ramp Greater Than Thread',\n",
    "    'Stand 3 - Operator Side Force',\n",
    "    'Flatness Control - Bending In Limit',\n",
    "    'Stand 1 Run Gap Setpoint',\n",
    "    'Stand 1 Gap Bite Offset',\n",
    "    'S1 Operating Bending Trim',\n",
    "    'Stand 2-3 Tension Reference',\n",
    "    'Neet Oil Concentration',\n",
    "    'Morgoil DriveTop Bearing Outflow Temp Stand1',\n",
    "    'Stand 4 Top Current Feedback',\n",
    "    'Morgoil DriveTop Bearing Outflow Temp Stand3',\n",
    "    'Stand 3 Run Gap Setpoint',\n",
    "    'Stand 2 Total Bending Feedback',\n",
    "    'Stand 2 Gap Bite Offset',\n",
    "    'Morgoil OperBottom Bearing Outflow Temp Stand3',\n",
    "    'Stand 4 Thread Gap Setpoint',\n",
    "    'X4 Gauge Deviation',\n",
    "    'Stand 4 DS Total Bending Feedback',\n",
    "    'Laser 0 Data Valid',\n",
    "    'Stand 4 - Operator Side Force',\n",
    "    'Stand 2 Gap Eccentricity Trim',\n",
    "    'Stand 4 Gap Operator Offset',\n",
    "    'Stand 3 Total Bending Feedback',\n",
    "    'Strip In Stand 3',\n",
    "    'Morgoil OperTop Bearing Outflow Temp Stand1',\n",
    "    'Strip In Stand 1',\n",
    "    'X1 Gauge Deviation',\n",
    "    'Stand 3 Drive Speed Feedback',\n",
    "    'Stand 2 Gap Thread Offset',\n",
    "    'Stand 2 Drive Speed Feedback',\n",
    "    'Stand 1-3 Solution System Pressure',\n",
    "    'Stand 2 Top Current Feedback',\n",
    "    'Stand 1-3 Solution Temperature',\n",
    "    'AGC GE Feedforward Hardness Number',\n",
    "    'Stand 1 Total Bending Feedback',\n",
    "    'X0 Gauge Deviation',\n",
    "    'Stand 3 Bottom Current Feedback',\n",
    "    'Stand 4 Gap Eccentricity Trim',\n",
    "    'Stand 2 Gap Stick Offset',\n",
    "    'Stand 3-4 Tension Reference',\n",
    "    'Stand 4 Bottom Current Feedback',\n",
    "    'Stand 1 Bottom Current Feedback',\n",
    "    'Stand 3 Gap Thread Offset',\n",
    "    'Stand 2 Bottom Current Feedback',\n",
    "    'Stand 4 Solution System Pressure',\n",
    "    'Stand 3 Gap Eccentricity Trim',\n",
    "    'Stand 4 OS Total Bending Feedback',\n",
    "    'Stand 1 Gap Thread Offset',\n",
    "    'AGC Alex Dynamic Feedforward Hardness Number',\n",
    "    'Stand 3 Top Current Feedback',\n",
    "    'S2 Operating Bending Trim',\n",
    "    'Roll Force Hydraulic Tank Level Inches',\n",
    "    'Roll Force Hydraulics Pressure Feedback',\n",
    "    'Stand 1 Roll Force Increase Limit (based on predicted run force)',\n",
    "    'Stand 4 OS Bending Shape Trim',\n",
    "    'Stand 4 DS Bending Shape Trim'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e02281a8-038d-4cc3-b992-89460d634fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store coil data\n",
    "coil_data = []\n",
    "\n",
    "# Read all CSV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "        coil_id = df['STD4_ID'].iloc[0]\n",
    "        cm_width = df['CM_WIDTH'].iloc[0]\n",
    "        gauge = df['CP_X4GAUGE'].iloc[0]\n",
    "        reduction = df['Reduction'].iloc[0]\n",
    "\n",
    "        # Calculate mean for each signal\n",
    "        signal_means = {}\n",
    "        for sig in signal_names:\n",
    "            if sig in df.columns:\n",
    "                signal_means[sig] = df[sig].mean()\n",
    "            else:\n",
    "                signal_means[sig] = np.nan\n",
    "\n",
    "        # Append data\n",
    "        coil_data.append({\n",
    "            'coil_id': coil_id,\n",
    "            'CM_WIDTH': cm_width,\n",
    "            'CP_X4GAUGE': gauge,\n",
    "            'Reduction':reduction,\n",
    "            **signal_means\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7bcccf2-265d-4c10-a00c-d5257a655e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_10632\\1032667989.py:31: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  coils_df.groupby(['Width_Bin', 'Gauge_Bin','Reduction_Bin']).agg({'coil_id': 'count'}).reset_index(),\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "coils_df = pd.DataFrame(coil_data)\n",
    "\n",
    "# Create bins for CM_WIDTH and CP_X4GAUGE\n",
    "coils_df['Width_Bin'] = pd.cut(coils_df['CM_WIDTH'], bins=np.arange(coils_df['CM_WIDTH'].min(),\n",
    "                                                                   coils_df['CM_WIDTH'].max() + 10, 10))\n",
    "coils_df['Gauge_Bin'] = pd.cut(coils_df['CP_X4GAUGE'], bins=np.arange(coils_df['CP_X4GAUGE'].min(),\n",
    "                                                                     coils_df['CP_X4GAUGE'].max() + 0.02, 0.02))\n",
    "coils_df['Reduction_Bin'] = pd.cut(coils_df['Reduction'], bins=np.arange(coils_df['Reduction'].min(),\n",
    "                                                                     coils_df['Reduction'].max() + 10, 10))\n",
    "\n",
    "# Create a dataframe of unique bucket pairs\n",
    "unique_buckets = coils_df[['Width_Bin', 'Gauge_Bin','Reduction_Bin']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Assign numeric bucket ID\n",
    "unique_buckets['Bucket_ID'] = range(1, len(unique_buckets) + 1)\n",
    "\n",
    "# Merge bucket IDs back to coils_df\n",
    "coils_df = coils_df.merge(unique_buckets, on=['Width_Bin', 'Gauge_Bin','Reduction_Bin'], how='left')\n",
    "\n",
    "# Create a descriptive bucket name\n",
    "coils_df['Bucket_Name'] = (\n",
    "    'Bucket ' + coils_df['Bucket_ID'].astype(str) +\n",
    "    ': Width ' + coils_df['Width_Bin'].astype(str) +\n",
    "    ', Gauge ' + coils_df['Gauge_Bin'].astype(str)+\n",
    "    ', Reduction ' + coils_df['Reduction_Bin'].astype(str)\n",
    ")\n",
    "\n",
    "# Generate summary for each bucket\n",
    "bucket_summary = unique_buckets.merge(\n",
    "    coils_df.groupby(['Width_Bin', 'Gauge_Bin','Reduction_Bin']).agg({'coil_id': 'count'}).reset_index(),\n",
    "    on=['Width_Bin', 'Gauge_Bin','Reduction_Bin'], how='left'\n",
    ").rename(columns={'coil_id': 'Coil_Count'})\n",
    "\n",
    "bucket_summary['Bucket_Name'] = (\n",
    "    'Bucket ' + bucket_summary['Bucket_ID'].astype(str) +\n",
    "    ': Width ' + bucket_summary['Width_Bin'].astype(str) +\n",
    "    ', Gauge ' + bucket_summary['Gauge_Bin'].astype(str) +\n",
    "    ', Reduction ' + coils_df['Reduction_Bin'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc951381-d36a-470f-af45-805b48ceae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_7296\\3407310347.py:79: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  coils_df.groupby(['Width_Bin', 'Gauge_Bin', 'Reduction_Bin'])\n"
     ]
    }
   ],
   "source": [
    "coil_data = []\n",
    "\n",
    "# Loop through all CSV files (one per coil)\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(folder_path, filename))\n",
    "\n",
    "        coil_id = df['STD4_ID'].iloc[0]\n",
    "        cm_width = df['CM_WIDTH'].iloc[0]\n",
    "        gauge = df['CP_X4GAUGE'].iloc[0]\n",
    "        reduction = df['Reduction'].iloc[0]\n",
    "\n",
    "        # Ensure 'Phase' column exists in data\n",
    "        if 'Phase' not in df.columns:\n",
    "            raise ValueError(f\"Missing 'Phase' column in {filename}\")\n",
    "\n",
    "        # Loop over phases present in the CSV (e.g. Phase 1, Phase 2, Phase 3)\n",
    "        for phase in df['Phase'].unique():\n",
    "            phase_df = df[df['Phase'] == phase]\n",
    "\n",
    "            # Calculate signal-wise mean for this phase\n",
    "            signal_means = {\n",
    "                sig: phase_df[sig].mean() if sig in phase_df.columns else np.nan\n",
    "                for sig in signal_names\n",
    "            }\n",
    "\n",
    "            # Append one entry per phase\n",
    "            coil_data.append({\n",
    "                'coil_id': coil_id,\n",
    "                'Phase': phase,\n",
    "                'CM_WIDTH': cm_width,\n",
    "                'CP_X4GAUGE': gauge,\n",
    "                'Reduction': reduction,\n",
    "                **signal_means\n",
    "            })\n",
    "\n",
    "# Combine all coils into one dataframe\n",
    "coils_df = pd.DataFrame(coil_data)\n",
    "\n",
    "# ------------------------------\n",
    "# Create bin columns for width, gauge, reduction\n",
    "# ------------------------------\n",
    "coils_df['Width_Bin'] = pd.cut(\n",
    "    coils_df['CM_WIDTH'],\n",
    "    bins=np.arange(coils_df['CM_WIDTH'].min(), coils_df['CM_WIDTH'].max() + 10, 10)\n",
    ")\n",
    "coils_df['Gauge_Bin'] = pd.cut(\n",
    "    coils_df['CP_X4GAUGE'],\n",
    "    bins=np.arange(coils_df['CP_X4GAUGE'].min(), coils_df['CP_X4GAUGE'].max() + 0.02, 0.02)\n",
    ")\n",
    "coils_df['Reduction_Bin'] = pd.cut(\n",
    "    coils_df['Reduction'],\n",
    "    bins=np.arange(coils_df['Reduction'].min(), coils_df['Reduction'].max() + 10, 10)\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Create unique bucket IDs\n",
    "# ------------------------------\n",
    "unique_buckets = coils_df[['Width_Bin', 'Gauge_Bin', 'Reduction_Bin']].drop_duplicates().reset_index(drop=True)\n",
    "unique_buckets['Bucket_ID'] = range(1, len(unique_buckets) + 1)\n",
    "\n",
    "# Merge bucket IDs back\n",
    "coils_df = coils_df.merge(unique_buckets, on=['Width_Bin', 'Gauge_Bin', 'Reduction_Bin'], how='left')\n",
    "\n",
    "# ------------------------------\n",
    "# Create descriptive bucket names\n",
    "# ------------------------------\n",
    "coils_df['Bucket_Name'] = (\n",
    "    'Bucket ' + coils_df['Bucket_ID'].astype(str) +\n",
    "    ': Width ' + coils_df['Width_Bin'].astype(str) +\n",
    "    ', Gauge ' + coils_df['Gauge_Bin'].astype(str) +\n",
    "    ', Reduction ' + coils_df['Reduction_Bin'].astype(str)\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# Optional: Bucket summary\n",
    "# ------------------------------\n",
    "bucket_summary = (\n",
    "    coils_df.groupby(['Width_Bin', 'Gauge_Bin', 'Reduction_Bin'])\n",
    "    .agg(Coil_Count=('coil_id', 'nunique'))\n",
    "    .reset_index()\n",
    "    .merge(unique_buckets, on=['Width_Bin', 'Gauge_Bin', 'Reduction_Bin'], how='left')\n",
    ")\n",
    "\n",
    "bucket_summary['Bucket_Name'] = (\n",
    "    'Bucket ' + bucket_summary['Bucket_ID'].astype(str) +\n",
    "    ': Width ' + bucket_summary['Width_Bin'].astype(str) +\n",
    "    ', Gauge ' + bucket_summary['Gauge_Bin'].astype(str) +\n",
    "    ', Reduction ' + bucket_summary['Reduction_Bin'].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175a9a02-3a3a-40f4-bfc3-2c0407eb89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Files saved: 'coil_signal_averages.csv' and 'bucket_properties.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save coil data with averages\n",
    "coils_df.to_csv('bucket_coil_signal_averages_allsignals_phasewise.csv', index=False)\n",
    "\n",
    "# Save bucket summaries\n",
    "bucket_summary.to_csv('bucket_properties_allsignals_phasewise.csv', index=False)\n",
    "\n",
    "print(\"Processing complete. Files saved: 'coil_signal_averages.csv' and 'bucket_properties.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6e6ba-fc15-4571-8d1e-6b35f04b3c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
