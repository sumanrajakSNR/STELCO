{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af372d80-94c7-4ec7-a93b-68f0d7acf7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good Shape 1008GCQ - Folder 1, 2, 3, 4, 5, 6, 7, 8, 9 ,10\n",
    "# Shape Rework\n",
    "# Shape Divert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5280646-b14a-4861-b421-bd6a7bc4a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# signal_features = ['X4 Gauge Deviation',\n",
    "#               'Master Ramp', 'Stand 1 Gap Operator Offset', 'Stand 2 Gap Operator Offset',\n",
    "#                  'Stand 3 Gap Operator Offset', 'Stand 4 Gap Operator Offset', 'S1 Operating Bending Trim', 'S2 Operating Bending Trim',\n",
    "#                  'S3 Operating Bending Trim', 'S4 Operating Bending Trim',\n",
    "#                'X0 Gauge Deviation', 'X1 Gauge Deviation',\n",
    "#                'Stand 1-2 Tension Reference', 'Stand 2-3 Tension Reference', 'Stand 3-4 Tension Reference', 'Stand 1-2 Total Tension Feedback',\n",
    "#                  'Stand 2-3 Total Tension Feedback', 'Stand 3-4 Total Tension Feedback', 'Exit Tension Reel Tension Reference',\n",
    "#                  'Tension Reel Calculated Tension', 'Stand 1 Gap Bite Offset', 'Stand 1 Gap Stick Offset', 'Stand 1 Gap Thread Offset',\n",
    "#                  'Stand 1 Thread Gap Setpoint', 'Stand 1 Run Gap Setpoint', 'Stand 2 Gap Bite Offset', 'Stand 2 Gap Stick Offset',\n",
    "#                  'Stand 2 Gap Thread Offset', 'Stand 2 Thread Gap Setpoint', 'Stand 2 Run Gap Setpoint', 'Stand 3 Gap Bite Offset',\n",
    "#                  'Stand 3 Gap Stick Offset', 'Stand 3 Gap Thread Offset', 'Stand 3 Thread Gap Setpoint', 'Stand 3 Run Gap Setpoint',\n",
    "#                  'Stand 4 Gap Bite Offset', 'Stand 4 Gap Stick Offset', 'Stand 4 Gap Thread Offset', 'Stand 4 Thread Gap Setpoint',\n",
    "#                  'Stand 4 Run Gap Setpoint', 'Stand 1 Predicted Run Force', 'Stand 2 Predicted Run Force', 'Stand 3 Predicted Run Force',\n",
    "#                  'Stand 4 Predicted Run Force', 'Stand 1 - Total Force', 'Stand 2 - Total Force', 'Stand 2 - Total Force', 'Stand 2 - Total Force',\n",
    "#                  'Stand 1 Top Current Feedback', 'Stand 2 Top Current Feedback', 'Stand 3 Top Current Feedback', 'Stand 4 Top Current Feedback',\n",
    "#                  'Stand 1 Bottom Current Feedback', 'Stand 2 Bottom Current Feedback', 'Stand 3 Bottom Current Feedback', 'Stand 4 Bottom Current Feedback',\n",
    "#                  'Master Ramp', 'AGC GE Feedforward Hardness Number', 'AGC Alex Dynamic Feedforward Hardness Number', 'Stand 1 Total Bending Feedback',\n",
    "#                  'Stand 2 Total Bending Feedback', 'Stand 3 Total Bending Feedback', 'Stand 4 OS Total Bending Feedback', 'Stand 4 DS Total Bending Feedback', 'Stand 1 - Operator Side Force', \n",
    "#                  'Stand 1 - Drive Side Force', 'Stand 2 - Operator Side Force', 'Stand 2 - Drive Side Force', 'Stand 3 - Operator Side Force',  'Stand 3 - Drive Side Force', \n",
    "#                  'Stand 4 - Operator Side Force', 'Stand 4 - Drive Side Force', 'Stand 1-2 Total Tension Feedback', 'Stand 2-3 Total Tension Feedback', 'Stand 3-4 Total Tension Feedback',\n",
    "#                  'Stand 1 Drive Speed Feedback', 'Stand 2 Drive Speed Feedback', 'Stand 3 Drive Speed Feedback', 'Stand 4 Drive Speed Feedback',\n",
    "#                'Neet Oil Concentration', 'Stand 1-3 Solution Temperature', 'Stand 1-3 Solution System Pressure',\n",
    "#                  'Stand 4 Solution System Pressure', 'Stand 1 Gap Eccentricity Trim', 'Stand 2 Gap Eccentricity Trim',\n",
    "#                  'Stand 3 Gap Eccentricity Trim', 'Stand 4 Gap Eccentricity Trim', 'Morgoil OperBottom Bearing Outflow Temp Stand1',\n",
    "#                  'Morgoil OperTop Bearing Outflow Temp Stand1', 'Morgoil DriveBottom Bearing Outflow Temp Stand1',\n",
    "#                  'Morgoil DriveTop Bearing Outflow Temp Stand1', 'Morgoil OperBottom Bearing Outflow Temp Stand2',\n",
    "#                  'Morgoil OperTop Bearing Outflow Temp Stand2', 'Morgoil DriveBottom Bearing Outflow Temp Stand2',\n",
    "#                  'Morgoil DriveTop Bearing Outflow Temp Stand2', 'Morgoil OperBottom Bearing Outflow Temp Stand3',\n",
    "                 # 'Morgoil OperTop Bearing Outflow Temp Stand3', 'Morgoil DriveBottom Bearing Outflow Temp Stand3',\n",
    "                 # 'Morgoil DriveTop Bearing Outflow Temp Stand3', 'Morgoil OperBottom Bearing Outflow Temp Stand4',\n",
    "                 # 'Morgoil OperTop Bearing Outflow Temp Stand4', 'Morgoil DriveBottom Bearing Outflow Temp Stand4',\n",
    "                 # 'Morgoil DriveTop Bearing Outflow Temp Stand4']\n",
    "shape_features = [\n",
    "    \"Operator_Q_VW\", \"Q1_Q_VW\", \"Center_Q_VW\", \"Q2_Q_VW\", \"Driver_Q_VW\", \"first_Q_VW\", \"second_Q_VW\", \"third_Q_VW\"\n",
    "]\n",
    "\n",
    "std_4_features = std_4_features = [\n",
    "    'Stand 1 Drive Speed Feedback', 'Stand 2 Drive Speed Feedback', 'Stand 3 Drive Speed Feedback',\n",
    "    'Stand 1 Top Current Feedback', 'Stand 2 Top Current Feedback', 'Stand 3 Top Current Feedback',\n",
    "    'Stand 1 Bottom Current Feedback', 'Stand 2 Bottom Current Feedback', 'Stand 3 Bottom Current Feedback',\n",
    "    'Stand 1 - Operator Side Force', 'Stand 2 - Operator Side Force', 'Stand 3 - Operator Side Force',\n",
    "    'Stand 1 - Drive Side Force', 'Stand 2 - Drive Side Force', 'Stand 3 - Drive Side Force',\n",
    "    'Morgoil OperBottom Bearing Outflow Temp Stand1', 'Morgoil OperBottom Bearing Outflow Temp Stand2',\n",
    "    'Morgoil OperBottom Bearing Outflow Temp Stand3',\n",
    "    'Morgoil OperTop Bearing Outflow Temp Stand1', 'Morgoil OperTop Bearing Outflow Temp Stand2',\n",
    "    'Morgoil OperTop Bearing Outflow Temp Stand3',\n",
    "    'Morgoil DriveBottom Bearing Outflow Temp Stand1', 'Morgoil DriveBottom Bearing Outflow Temp Stand2',\n",
    "    'Morgoil DriveBottom Bearing Outflow Temp Stand3',\n",
    "    'Morgoil DriveTop Bearing Outflow Temp Stand1', 'Morgoil DriveTop Bearing Outflow Temp Stand2',\n",
    "    'Morgoil DriveTop Bearing Outflow Temp Stand3', \n",
    "    'Stand 1 Gap Operator Offset', 'Stand 2 Gap Operator Offset', 'Stand 3 Gap Operator Offset'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a31f7c-bd70-4ac7-ad6f-04e5d407d5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "['Stand 1 Drive Speed Feedback', 'Stand 2 Drive Speed Feedback', 'Stand 3 Drive Speed Feedback', 'Stand 1 Top Current Feedback', 'Stand 2 Top Current Feedback', 'Stand 3 Top Current Feedback', 'Stand 1 Bottom Current Feedback', 'Stand 2 Bottom Current Feedback', 'Stand 3 Bottom Current Feedback', 'Stand 1 - Operator Side Force', 'Stand 2 - Operator Side Force', 'Stand 3 - Operator Side Force', 'Stand 1 - Drive Side Force', 'Stand 2 - Drive Side Force', 'Stand 3 - Drive Side Force', 'Morgoil OperBottom Bearing Outflow Temp Stand1', 'Morgoil OperBottom Bearing Outflow Temp Stand2', 'Morgoil OperBottom Bearing Outflow Temp Stand3', 'Morgoil OperTop Bearing Outflow Temp Stand1', 'Morgoil OperTop Bearing Outflow Temp Stand2', 'Morgoil OperTop Bearing Outflow Temp Stand3', 'Morgoil DriveBottom Bearing Outflow Temp Stand1', 'Morgoil DriveBottom Bearing Outflow Temp Stand2', 'Morgoil DriveBottom Bearing Outflow Temp Stand3', 'Morgoil DriveTop Bearing Outflow Temp Stand1', 'Morgoil DriveTop Bearing Outflow Temp Stand2', 'Morgoil DriveTop Bearing Outflow Temp Stand3', 'Stand 1 Gap Operator Offset', 'Stand 2 Gap Operator Offset', 'Stand 3 Gap Operator Offset']\n"
     ]
    }
   ],
   "source": [
    "# std_4_features = [feature for feature in signal_features if 'Stand 4' in feature or \"S4\" in feature or 'Stand4' in feature]\n",
    "print(len(std_4_features))\n",
    "print(std_4_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2ccb91-975f-4f55-a8f2-306d1746e52a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of files in Good_Shape 1008GCQ : 200\n",
      "\n",
      "=== Starting Folder: Good_Shape 1008GCQ | Time: 2025-05-09 08:27:30 ===\n",
      "Processing: 5485837.csv\n",
      "Processing: 5481202.csvProcessing: 5479608.csvProcessing: 5479605.csvProcessing: 5480224.csvProcessing: 5484421.csvProcessing: 5484756.csvProcessing: 5482950.csvProcessing: 5478862.csvProcessing: 5475091.csvProcessing: 5486297.csvProcessing: 5486166.csvProcessing: 5485870.csvProcessing: 5477252.csvProcessing: 5486271.csvProcessing: 5480107.csv\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Finished: 5479605.csv in 63.15 seconds.\n",
      "Processing: 5483048.csv\n",
      "Finished: 5486166.csv in 131.35 seconds.\n",
      "Processing: 5481225.csv\n",
      "Finished: 5484421.csv in 141.11 seconds.\n",
      "Processing: 5481192.csv\n",
      "Finished: 5486297.csv in 148.58 seconds.\n",
      "Processing: 5479595.csv\n",
      "Finished: 5482950.csv in 151.41 seconds.\n",
      "Processing: 5486125.csv\n",
      "Finished: 5479608.csv in 165.68 seconds.\n",
      "Processing: 5479480.csv\n",
      "Finished: 5481202.csv in 168.72 seconds.\n",
      "Processing: 5486583.csv\n",
      "Finished: 5484756.csv in 178.44 seconds.\n",
      "Processing: 5486643.csv\n",
      "Finished: 5480107.csv in 183.29 seconds.\n",
      "Processing: 5476849.csv\n",
      "Finished: 5478862.csv in 217.10 seconds.\n",
      "Processing: 5483016.csv\n",
      "Finished: 5483048.csv in 162.80 seconds.\n",
      "Processing: 5476967.csv\n",
      "Finished: 5486271.csv in 239.93 seconds.\n",
      "Processing: 5474268.csv\n",
      "Finished: 5485870.csv in 249.11 seconds.\n",
      "Processing: 5480000.csv\n",
      "Finished: 5485837.csv in 252.58 seconds.\n",
      "Processing: 5484248.csv\n",
      "Finished: 5481192.csv in 148.35 seconds.\n",
      "Processing: 5486698.csv\n",
      "Finished: 5481225.csv in 171.34 seconds.\n",
      "Processing: 5486548.csv\n",
      "Finished: 5479480.csv in 138.11 seconds.\n",
      "Processing: 5485763.csv\n",
      "Finished: 5479595.csv in 164.11 seconds.\n",
      "Processing: 5485861.csv\n",
      "Finished: 5486583.csv in 162.64 seconds.\n",
      "Processing: 5479995.csv\n",
      "Finished: 5477252.csv in 341.20 seconds.\n",
      "Processing: 5481186.csv\n",
      "Finished: 5480224.csv in 362.68 seconds.\n",
      "Processing: 5484904.csv\n",
      "Finished: 5486643.csv in 193.93 seconds.\n",
      "Processing: 5474255.csv\n",
      "Finished: 5486125.csv in 240.25 seconds.\n",
      "Processing: 5486503.csv\n",
      "Finished: 5483016.csv in 174.84 seconds.\n",
      "Processing: 5477205.csv\n",
      "Finished: 5484248.csv in 156.50 seconds.\n",
      "Processing: 5479381.csv\n",
      "Finished: 5476849.csv in 258.13 seconds.\n",
      "Processing: 5476854.csv\n",
      "Finished: 5486548.csv in 177.84 seconds.\n",
      "Processing: 5480227.csv\n",
      "Finished: 5486698.csv in 193.63 seconds.\n",
      "Processing: 5480218.csv\n",
      "Finished: 5475091.csv in 489.43 seconds.\n",
      "Processing: 5479567.csv\n",
      "Finished: 5481186.csv in 158.31 seconds.\n",
      "Processing: 5474590.csv\n",
      "Finished: 5474255.csv in 132.63 seconds.\n",
      "Processing: 5483501.csv\n",
      "Finished: 5480000.csv in 258.96 seconds.\n",
      "Processing: 5484948.csv\n",
      "Finished: 5474268.csv in 299.05 seconds.\n",
      "Processing: 5486406.csv\n",
      "Finished: 5485861.csv in 233.54 seconds.\n",
      "Processing: 5480699.csv\n",
      "Finished: 5486503.csv in 157.34 seconds.\n",
      "Processing: 5479968.csv\n",
      "Finished: 5477205.csv in 186.85 seconds.\n",
      "Processing: 5477258.csv\n",
      "Finished: 5485763.csv in 277.82 seconds.\n",
      "Processing: 5477257.csv\n",
      "Finished: 5484904.csv in 242.20 seconds.\n",
      "Processing: 5476844.csv\n",
      "Finished: 5479381.csv in 199.99 seconds.\n",
      "Processing: 5479581.csv\n",
      "Finished: 5476854.csv in 178.62 seconds.\n",
      "Processing: 5486283.csv\n",
      "Finished: 5483501.csv in 148.53 seconds.\n",
      "Processing: 5481197.csv\n",
      "Finished: 5480227.csv in 177.64 seconds.\n",
      "Processing: 5485799.csv\n",
      "Finished: 5476967.csv in 449.58 seconds.\n",
      "Processing: 5486144.csv\n",
      "Finished: 5479567.csv in 226.08 seconds.\n",
      "Processing: 5477196.csv\n",
      "Finished: 5477257.csv in 144.06 seconds.\n",
      "Processing: 5486559.csv\n",
      "Finished: 5480699.csv in 188.51 seconds.\n",
      "Processing: 5484032.csv\n",
      "Finished: 5486406.csv in 197.44 seconds.\n",
      "Processing: 5480483.csv\n",
      "Finished: 5477258.csv in 157.67 seconds.\n",
      "Processing: 5476487.csv\n",
      "Finished: 5479581.csv in 135.98 seconds.\n",
      "Processing: 5474304.csv\n",
      "Finished: 5484948.csv in 244.57 seconds.\n",
      "Processing: 5479988.csv\n",
      "Finished: 5479968.csv in 209.50 seconds.\n",
      "Processing: 5480007.csv\n",
      "Finished: 5476844.csv in 181.68 seconds.\n",
      "Processing: 5486575.csv\n",
      "Finished: 5479995.csv in 460.27 seconds.\n",
      "Processing: 5484373.csv\n",
      "Finished: 5486283.csv in 198.04 seconds.\n",
      "Processing: 5485832.csv\n",
      "Finished: 5480218.csv in 356.49 seconds.\n",
      "Processing: 5479757.csv\n",
      "Finished: 5474590.csv in 342.43 seconds.\n",
      "Processing: 5486800.csv\n",
      "Finished: 5485799.csv in 239.05 seconds.\n",
      "Processing: 5486258.csv\n",
      "Finished: 5480483.csv in 161.27 seconds.\n",
      "Processing: 5485844.csv\n",
      "Finished: 5486559.csv in 176.10 seconds.\n",
      "Processing: 5476855.csv\n",
      "Finished: 5474304.csv in 160.24 seconds.\n",
      "Processing: 5484557.csv\n",
      "Finished: 5484032.csv in 175.91 seconds.\n",
      "Processing: 5476944.csv\n",
      "Finished: 5486144.csv in 252.93 seconds.\n",
      "Processing: 5486399.csv\n",
      "Finished: 5486575.csv in 168.16 seconds.\n",
      "Processing: 5474608.csv\n",
      "Finished: 5479988.csv in 206.44 seconds.\n",
      "Processing: 5485738.csv\n",
      "Finished: 5481197.csv in 307.14 seconds.\n",
      "Processing: 5486543.csv\n",
      "Finished: 5484373.csv in 178.16 seconds.\n",
      "Processing: 5486128.csv\n",
      "Finished: 5486800.csv in 147.44 seconds.\n",
      "Processing: 5486275.csv\n",
      "Finished: 5480007.csv in 242.06 seconds.\n",
      "Processing: 5474235.csv\n",
      "Finished: 5479757.csv in 192.73 seconds.\n",
      "Processing: 5479602.csv\n",
      "Finished: 5477196.csv in 344.64 seconds.\n",
      "Processing: 5486277.csv\n",
      "Finished: 5486258.csv in 163.60 seconds.\n",
      "Processing: 5484363.csv\n",
      "Finished: 5484557.csv in 160.45 seconds.\n",
      "Processing: 5485759.csv\n",
      "Finished: 5485832.csv in 265.09 seconds.\n",
      "Processing: 5486252.csv\n",
      "Finished: 5474608.csv in 131.53 seconds.\n",
      "Processing: 5481191.csv\n",
      "Finished: 5485844.csv in 228.30 seconds.\n",
      "Processing: 5479987.csv\n",
      "Finished: 5476487.csv in 394.89 seconds.\n",
      "Processing: 5482478.csv\n",
      "Finished: 5486543.csv in 171.25 seconds.\n",
      "Processing: 5485687.csv\n",
      "Finished: 5474235.csv in 144.43 seconds.\n",
      "Processing: 5481198.csv\n",
      "Finished: 5476944.csv in 236.64 seconds.\n",
      "Processing: 5476864.csv\n",
      "Finished: 5486399.csv in 220.77 seconds.\n",
      "Processing: 5485600.csv\n",
      "Finished: 5476855.csv in 280.84 seconds.\n",
      "Processing: 5476347.csv\n",
      "Finished: 5479602.csv in 156.66 seconds.\n",
      "Processing: 5486411.csv\n",
      "Finished: 5486128.csv in 226.35 seconds.\n",
      "Processing: 5479380.csv\n",
      "Finished: 5485738.csv in 255.87 seconds.\n",
      "Processing: 5479791.csv\n",
      "Finished: 5484363.csv in 169.19 seconds.\n",
      "Processing: 5483013.csv\n",
      "Finished: 5486275.csv in 242.03 seconds.\n",
      "Processing: 5479998.csv\n",
      "Finished: 5481191.csv in 161.40 seconds.\n",
      "Processing: 5484129.csv\n",
      "Finished: 5486277.csv in 205.04 seconds.\n",
      "Processing: 5484559.csv\n",
      "Finished: 5479987.csv in 151.17 seconds.\n",
      "Processing: 5479589.csv\n",
      "Finished: 5482478.csv in 161.54 seconds.\n",
      "Processing: 5486511.csv\n",
      "Finished: 5481198.csv in 162.74 seconds.\n",
      "Processing: 5486302.csv\n",
      "Finished: 5479791.csv in 103.48 seconds.\n",
      "Processing: 5484039.csv\n",
      "Finished: 5476864.csv in 180.80 seconds.\n",
      "Processing: 5478891.csv\n",
      "Finished: 5485759.csv in 280.56 seconds.\n",
      "Processing: 5474226.csv\n",
      "Finished: 5485687.csv in 269.90 seconds.\n",
      "Processing: 5474298.csv\n",
      "Finished: 5479380.csv in 221.04 seconds.\n",
      "Processing: 5486308.csv\n",
      "Finished: 5486411.csv in 240.81 seconds.\n",
      "Processing: 5484738.csv\n",
      "Finished: 5486302.csv in 153.04 seconds.\n",
      "Processing: 5480009.csv\n",
      "Finished: 5486252.csv in 386.98 seconds.\n",
      "Processing: 5474602.csv\n",
      "Finished: 5479998.csv in 244.00 seconds.\n",
      "Processing: 5484879.csv\n",
      "Finished: 5474226.csv in 133.09 seconds.\n",
      "Processing: 5484870.csv\n",
      "Finished: 5478891.csv in 199.51 seconds.\n",
      "Processing: 5486648.csv\n",
      "Finished: 5479589.csv in 264.74 seconds.\n",
      "Processing: 5476948.csv\n",
      "Finished: 5484559.csv in 276.83 seconds.\n",
      "Processing: 5486137.csv\n",
      "Finished: 5484039.csv in 225.20 seconds.\n",
      "Processing: 5476363.csv\n",
      "Finished: 5486308.csv in 162.31 seconds.\n",
      "Processing: 5486131.csv\n",
      "Finished: 5476347.csv in 397.07 seconds.\n",
      "Processing: 5475062.csv\n",
      "Finished: 5483013.csv in 354.97 seconds.\n",
      "Processing: 5480809.csv\n",
      "Finished: 5474602.csv in 151.65 seconds.\n",
      "Processing: 5483196.csv\n",
      "Finished: 5484129.csv in 393.64 seconds.\n",
      "Processing: 5485840.csv\n",
      "Finished: 5484738.csv in 246.45 seconds.\n",
      "Processing: 5486535.csv\n",
      "Finished: 5486137.csv in 146.87 seconds.\n",
      "Processing: 5486130.csv\n",
      "Finished: 5474298.csv in 314.26 seconds.\n",
      "Processing: 5480237.csv\n",
      "Finished: 5486648.csv in 200.27 seconds.\n",
      "Processing: 5484912.csv\n",
      "Finished: 5483196.csv in 117.98 seconds.\n",
      "Processing: 5483506.csv\n",
      "Finished: 5485600.csv in 597.04 seconds.\n",
      "Processing: 5480640.csv\n",
      "Finished: 5476363.csv in 202.91 seconds.\n",
      "Processing: 5484952.csv\n",
      "Finished: 5486131.csv in 209.51 seconds.\n",
      "Processing: 5485742.csv\n",
      "Finished: 5475062.csv in 259.86 seconds.\n",
      "Processing: 5480134.csv\n",
      "Finished: 5486535.csv in 171.80 seconds.\n",
      "Processing: 5476859.csv\n",
      "Finished: 5484870.csv in 386.71 seconds.\n",
      "Processing: 5485866.csv\n",
      "Finished: 5480237.csv in 163.28 seconds.\n",
      "Processing: 5485852.csv\n",
      "Finished: 5486130.csv in 192.61 seconds.\n",
      "Processing: 5477255.csv\n",
      "Finished: 5480640.csv in 169.16 seconds.\n",
      "Processing: 5476819.csv\n",
      "Finished: 5484912.csv in 230.37 seconds.\n",
      "Processing: 5486108.csv\n",
      "Finished: 5485840.csv in 322.10 seconds.\n",
      "Processing: 5484118.csv\n",
      "Finished: 5476948.csv in 434.69 seconds.\n",
      "Processing: 5476846.csv\n",
      "Finished: 5480009.csv in 519.07 seconds.\n",
      "Processing: 5480232.csv\n",
      "Finished: 5484879.csv in 505.11 seconds.\n",
      "Processing: 5486122.csv\n",
      "Finished: 5477255.csv in 147.42 seconds.\n",
      "Processing: 5483006.csv\n",
      "Finished: 5476859.csv in 186.68 seconds.\n",
      "Processing: 5479575.csv\n",
      "Finished: 5479575.csv in 2.71 seconds.\n",
      "Processing: 5474247.csv\n",
      "Finished: 5480134.csv in 197.92 seconds.\n",
      "Processing: 5475252.csv\n",
      "Finished: 5485742.csv in 255.45 seconds.\n",
      "Processing: 5484369.csv\n",
      "Finished: 5480809.csv in 463.61 seconds.\n",
      "Processing: 5486553.csv\n",
      "Finished: 5486511.csv in 774.34 seconds.\n",
      "Processing: 5486565.csv\n",
      "Finished: 5483506.csv in 365.87 seconds.\n",
      "Processing: 5476871.csv\n",
      "Finished: 5485866.csv in 256.18 seconds.\n",
      "Processing: 5485806.csv\n",
      "Finished: 5476819.csv in 208.90 seconds.\n",
      "Processing: 5486135.csv\n",
      "Finished: 5485852.csv in 247.84 seconds.\n",
      "Processing: 5480210.csv\n",
      "Finished: 5486108.csv in 184.39 seconds.\n",
      "Processing: 5479601.csv\n",
      "Finished: 5484118.csv in 180.30 seconds.\n",
      "Processing: 5481195.csv\n",
      "Finished: 5480232.csv in 170.61 seconds.\n",
      "Processing: 5477256.csv\n",
      "Finished: 5474247.csv in 132.04 seconds.\n",
      "Processing: 5474262.csv\n",
      "Finished: 5486122.csv in 201.93 seconds.\n",
      "Processing: 5486404.csv\n",
      "Finished: 5476846.csv in 219.07 seconds.\n",
      "Processing: 5477254.csv\n",
      "Finished: 5484369.csv in 167.32 seconds.\n",
      "Processing: 5482956.csv\n",
      "Finished: 5475252.csv in 176.12 seconds.\n",
      "Processing: 5474083.csv\n",
      "Finished: 5483006.csv in 187.07 seconds.\n",
      "Processing: 5486694.csv\n",
      "Finished: 5486565.csv in 170.93 seconds.\n",
      "Processing: 5479077.csv\n",
      "Finished: 5486553.csv in 192.77 seconds.\n",
      "Processing: 5486796.csv\n",
      "Finished: 5476871.csv in 180.72 seconds.\n",
      "Processing: 5484111.csv\n",
      "Finished: 5480210.csv in 165.89 seconds.\n",
      "Processing: 5486327.csv\n",
      "Finished: 5474262.csv in 130.11 seconds.\n",
      "Processing: 5476850.csv\n",
      "Finished: 5479601.csv in 158.95 seconds.\n",
      "Processing: 5479375.csv\n",
      "Finished: 5477256.csv in 152.04 seconds.\n",
      "Processing: 5479072.csv\n",
      "Finished: 5477254.csv in 155.29 seconds.\n",
      "Processing: 5482955.csv\n",
      "Finished: 5474083.csv in 146.00 seconds.\n",
      "Processing: 5474299.csv\n",
      "Finished: 5486135.csv in 244.69 seconds.\n",
      "Processing: 5480827.csv\n",
      "Finished: 5482956.csv in 160.19 seconds.\n",
      "Processing: 5482968.csv\n",
      "Finished: 5486694.csv in 157.72 seconds.\n",
      "Processing: 5484895.csv\n",
      "Finished: 5485806.csv in 273.29 seconds.\n",
      "Processing: 5483054.csv\n",
      "Finished: 5486404.csv in 240.91 seconds.\n",
      "Processing: 5486114.csv\n",
      "Finished: 5479077.csv in 223.08 seconds.\n",
      "Processing: 5486334.csv\n",
      "Finished: 5486327.csv in 182.31 seconds.\n",
      "Processing: 5486141.csv\n",
      "Finished: 5484111.csv in 190.37 seconds.\n",
      "Processing: 5484361.csv\n",
      "Finished: 5476850.csv in 189.32 seconds.\n",
      "Processing: 5475310.csv\n",
      "Finished: 5479375.csv in 202.71 seconds.\n",
      "Processing: 5485755.csv\n",
      "Finished: 5485755.csv in 4.51 seconds.\n",
      "Processing: 5484124.csv\n",
      "Finished: 5481195.csv in 368.33 seconds.\n",
      "Processing: 5474088.csv\n",
      "Finished: 5474299.csv in 165.17 seconds.\n",
      "Processing: 5478797.csv\n",
      "Finished: 5482968.csv in 161.59 seconds.\n",
      "Processing: 5474616.csv\n",
      "Finished: 5480827.csv in 224.55 seconds.\n",
      "Processing: 5484767.csv\n",
      "Finished: 5486796.csv in 358.09 seconds.\n",
      "Processing: 5485331.csv\n",
      "Finished: 5484895.csv in 243.02 seconds.\n",
      "Processing: 5486688.csv\n",
      "Finished: 5486114.csv in 197.69 seconds.\n",
      "Processing: 5482412.csv\n",
      "Finished: 5484361.csv in 179.01 seconds.\n",
      "Processing: 5481193.csv\n",
      "Finished: 5486334.csv in 204.85 seconds.\n",
      "Processing: 5486522.csv\n",
      "Finished: 5474088.csv in 160.83 seconds.\n",
      "Processing: 5476867.csv\n",
      "Finished: 5475310.csv in 189.09 seconds.\n",
      "Processing: 5485772.csv\n",
      "Finished: 5484952.csv in 934.77 seconds.\n",
      "Processing: 5484762.csv\n",
      "Finished: 5478797.csv in 180.38 seconds.\n",
      "Processing: 5484036.csv\n",
      "Finished: 5486141.csv in 242.69 seconds.\n",
      "Processing: 5477250.csv\n",
      "Finished: 5482955.csv in 379.67 seconds.\n",
      "Processing: 5485824.csv\n",
      "Finished: 5479072.csv in 475.90 seconds.\n",
      "Finished: 5484124.csv in 272.71 seconds.\n",
      "Finished: 5484767.csv in 195.28 seconds.\n",
      "Finished: 5483054.csv in 396.39 seconds.\n",
      "Finished: 5485331.csv in 196.15 seconds.\n",
      "Finished: 5481193.csv in 141.56 seconds.\n",
      "Finished: 5486522.csv in 149.85 seconds.\n",
      "Finished: 5476867.csv in 167.99 seconds.\n",
      "Finished: 5482412.csv in 244.51 seconds.\n",
      "Finished: 5484762.csv in 202.95 seconds.\n",
      "Finished: 5484036.csv in 232.37 seconds.\n",
      "Finished: 5485772.csv in 267.30 seconds.\n",
      "Finished: 5477250.csv in 241.96 seconds.\n",
      "Finished: 5485824.csv in 245.08 seconds.\n",
      "Finished: 5486688.csv in 375.24 seconds.\n",
      "Finished: 5474616.csv in 721.02 seconds.\n",
      "=== Finished Folder: Good_Shape 1008GCQ | Time: 2025-05-09 09:21:44 ===\n",
      "Total analyses for Good_Shape 1008GCQ: 48000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm  # Import tqdm for progress tracking\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor  # Import for multithreading\n",
    "from datetime import datetime\n",
    "from itertools import repeat  # Import repeat to pass additional arguments in ThreadPoolExecutor\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Compute rolling correlation (with the necessary modification to return total windows)\n",
    "def compute_rolling_correlation(continuous_signal, discrete_signal, window_size):\n",
    "    rolling_corr = []\n",
    "    total_windows = len(continuous_signal) - window_size + 1\n",
    "    for i in range(total_windows):\n",
    "        window_continuous = continuous_signal[i:i + window_size]\n",
    "        window_discrete = discrete_signal[i:i + window_size]\n",
    "        \n",
    "        # Calculate the standard deviations of the signals in the window\n",
    "        std_continuous = window_continuous.std()\n",
    "        std_discrete = window_discrete.std()\n",
    "        \n",
    "        # If either of the standard deviations is zero, set correlation to zero\n",
    "        if std_continuous == 0 or std_discrete == 0:\n",
    "            corr_value = 0\n",
    "        else:\n",
    "            corr_value = window_continuous.corr(window_discrete)\n",
    "        \n",
    "        rolling_corr.append(corr_value)\n",
    "    \n",
    "    return pd.Series(rolling_corr, index=continuous_signal.index[window_size - 1:]), total_windows\n",
    "\n",
    "# Analyze signals and include total window count, significant window count, and contribution factor\n",
    "def analyze_signals(df, continuous_col, discrete_col, coil_length_col, window_size=250, correlation_threshold=0.7):\n",
    "    # Convert the coil length column to numeric values if necessary\n",
    "    df[coil_length_col] = pd.to_numeric(df[coil_length_col], errors='coerce')\n",
    "    \n",
    "    coil_length_values = df[coil_length_col]\n",
    "    continuous_signal = df[continuous_col]\n",
    "    discrete_signal = df[discrete_col]\n",
    "\n",
    "    # Compute rolling correlation and total window count\n",
    "    rolling_corr, total_windows = compute_rolling_correlation(continuous_signal, discrete_signal, window_size)\n",
    "\n",
    "    # Add the rolling correlation values as a new column in the DataFrame\n",
    "    df[f'{continuous_col}_Rolling_Corr_{discrete_col}'] = pd.NA\n",
    "    df.loc[rolling_corr.index, f'{continuous_col}_Rolling_Corr_{discrete_col}'] = rolling_corr.astype(float)\n",
    "    \n",
    "    # Identify times where correlation is above threshold\n",
    "    above_threshold_indices = rolling_corr[rolling_corr.abs() >= correlation_threshold].index\n",
    "    significant_corr_count = len(above_threshold_indices)\n",
    "\n",
    "    # Calculate the contribution factor (the ratio of significant windows to total windows)\n",
    "    contribution_factor = significant_corr_count / total_windows if total_windows > 0 else 0\n",
    "\n",
    "    if significant_corr_count > 0:\n",
    "        # Compute average correlation using the absolute values to avoid cancellation of positive and negative values\n",
    "        average_corr = rolling_corr[above_threshold_indices].abs().mean()\n",
    "\n",
    "        # Min and Max correlation times (using coil length as reference)\n",
    "        min_index = coil_length_values.iloc[above_threshold_indices[0]]\n",
    "        max_index = coil_length_values.iloc[above_threshold_indices[-1]]\n",
    "        maximum_corr_index = coil_length_values.iloc[rolling_corr.abs().idxmax()]\n",
    "    else:\n",
    "        average_corr = 0\n",
    "        min_index = 0\n",
    "        max_index = 0\n",
    "        maximum_corr_index = 0\n",
    "\n",
    "    # Return results including total windows, significant window count, and contribution factor\n",
    "    return (significant_corr_count, average_corr, min_index, max_index, maximum_corr_index, total_windows, contribution_factor, df)\n",
    "\n",
    "# Process one file: add correlation columns and save to the same file\n",
    "def process_file(file_name, base_folder, signal_features, shape_features, coil_length_col, window_size, correlation_threshold, result_data):\n",
    "    start_time = time.time()\n",
    "    print(f\"Processing: {file_name}\")\n",
    "    file_path = os.path.join(base_folder, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    pickle_id = df[\"Coil ID\"].iloc[0]\n",
    "    coil_category, grade = base_folder.split(\" \")\n",
    "    another_result = []\n",
    "\n",
    "    # Create a copy of the original df to accumulate all correlations\n",
    "    updated_df = df.copy()\n",
    "\n",
    "    for iba in signal_features:\n",
    "        for shape in shape_features:\n",
    "            (significant_corr_count, average_corr, min_index, max_index, maximum_corr_index,\n",
    "             total_windows, contribution_factor, temp_df) = analyze_signals(\n",
    "                updated_df, iba, shape, coil_length_col, window_size, correlation_threshold\n",
    "            )\n",
    "\n",
    "            # Append results for further summary\n",
    "            another_result.append({\n",
    "                \"Coil ID\": pickle_id,\n",
    "                \"Coil Type\": coil_category,\n",
    "                \"Grade\": grade,\n",
    "                \"Signal Feature\": iba,\n",
    "                \"Shape Feature\": shape,\n",
    "                \"Total Windows\": total_windows,\n",
    "                \"Significant Correlation Window Count\": significant_corr_count,\n",
    "                \"Contribution Factor %\": f\"{contribution_factor * 100:.4f}\",\n",
    "                \"Average Correlation\": average_corr\n",
    "            })\n",
    "\n",
    "            # The rolling correlation columns are added in the temp_df, so we are updating updated_df\n",
    "            updated_df = temp_df\n",
    "\n",
    "    # Save the updated DataFrame with all rolling correlations after processing all signal pairs\n",
    "    updated_df.to_csv(file_path, index=False)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Finished: {file_name} in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # # Save the summary results for this file\n",
    "    # result_df = pd.DataFrame(another_result)\n",
    "    # result_df.to_csv(f\"{base_folder}_correlation_analysis_{file_name}.csv\", index=False)\n",
    "\n",
    "    return another_result\n",
    "\n",
    "# Process multiple folders\n",
    "def process_folders(base_folders, signal_features, shape_features, coil_length_col, window_size=250, correlation_threshold=0.7):\n",
    "    for base_folder in base_folders:\n",
    "        print(f\"No.of files in {base_folder} : {len([f for f in os.listdir(base_folder)])}\")\n",
    "        result_data = []\n",
    "        f_start = datetime.now()\n",
    "        print(f\"\\n=== Starting Folder: {base_folder} | Time: {f_start.strftime('%Y-%m-%d %H:%M:%S')} ===\")\n",
    "\n",
    "        path = os.path.join(base_folder)\n",
    "        files = [file for file in os.listdir(path) if file.endswith(\".csv\")]\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=min(16, len(files))) as executor:\n",
    "            results = list(executor.map(\n",
    "                process_file,\n",
    "                files,\n",
    "                repeat(base_folder),\n",
    "                repeat(signal_features),\n",
    "                repeat(shape_features),\n",
    "                repeat(coil_length_col),\n",
    "                repeat(window_size),\n",
    "                repeat(correlation_threshold),\n",
    "                repeat(result_data)\n",
    "            ))\n",
    "\n",
    "        f_end = datetime.now()\n",
    "        print(f\"=== Finished Folder: {base_folder} | Time: {f_end.strftime('%Y-%m-%d %H:%M:%S')} ===\")\n",
    "\n",
    "        flat_results = [item for sublist in results for item in sublist]\n",
    "        result_df = pd.DataFrame(flat_results)\n",
    "        print(f\"Total analyses for {base_folder}: {len(flat_results)}\")\n",
    "\n",
    "        result_df.to_csv(f\"correlation_analysis_for_{base_folder}_WithShape.csv\", index=False)\n",
    "\n",
    "# Example usage\n",
    "time_column = \"Coil Length [30ms]\"\n",
    "coil_types = [\"Good_Shape 1008GCQ\"]\n",
    "\n",
    "# Process all CSV files across different folders and save the results\n",
    "process_folders(coil_types, std_4_features, shape_features, time_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6470a9f5-e9ac-4f23-bc3d-1d70af88564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "max_workers = os.cpu_count()  # e.g., 16 on c5.4xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b72753bb-b2e7-4f64-ade0-d082c5e5e22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b59b10-4aa5-44a8-9247-f208ecb943da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
